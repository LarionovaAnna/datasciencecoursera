{
    "contents" : "---\ntitle: \"Course_project\"\noutput: html_document\n---\n##Info\n\nThe scripts have been solely produced, tested and executed on Windows XP SP2 and RStudio Version 0.98.1091.\n\nDeveloper: Anna Larionova\n\nGitHub repo: https://github.com/LarionovaAnna/datasciencecoursera\n\n\n## Report\n\nIn order to reproduce the same results, you need a certain set of packages, as well as setting a pseudo random seed equal to the one I used. \n*Note:To install, for instance, the caret package in R, run this command: install.packages(\"caret\")\n\nThe following Libraries were used for this project, which you should install - if not done yet - and load on your working environment.\n```{r}\nlibrary(caret)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nlibrary(rattle)\nlibrary(randomForest)\n```\n\nFinally, load the same seed with the following line of code:\n```{r}\nset.seed(12345)\n```\n\n## Getting the data\n\nThe training data set can be found on the following URL:\n\n```{r}\ntrainUrl <- \"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\n```\n\nThe testing data set can be found on the following URL:\n```{r}\ntestUrl <- \"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\n```\n\nLoad data to memory\n```{r}\noriginal_training <- read.csv(url(trainUrl), na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\noriginal_testing <- read.csv(url(testUrl), na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\n```\n\n##Partioning the training set into two\n\nPartitioning Training data set into two data sets, 60% for myTraining, 40% for myTesting:\n\n```{r}\ninTrain <- createDataPartition(y=original_training$classe, p=0.6, list=FALSE)\ntraining <- original_training[inTrain, ]; testing <- training[-inTrain, ]\ndim(training); dim(testing)\n```\n\n## Cleaning the data\n\nThe following transformations were used to clean the data:\n-cleaning NearZeroVariance Variables\nRun this code to view possible NZV Variables:\n```{r}\nNZVs <- nearZeroVar(training, saveMetrics=TRUE)\n```\n\nCreate subset without NZV variables:\n\n```{r}\nNZVvars <- names(training) %in% c(\"new_window\", \"kurtosis_roll_belt\", \"kurtosis_picth_belt\",\n\"kurtosis_yaw_belt\", \"skewness_roll_belt\", \"skewness_roll_belt.1\", \"skewness_yaw_belt\",\n\"max_yaw_belt\", \"min_yaw_belt\", \"amplitude_yaw_belt\", \"avg_roll_arm\", \"stddev_roll_arm\",\n\"var_roll_arm\", \"avg_pitch_arm\", \"stddev_pitch_arm\", \"var_pitch_arm\", \"avg_yaw_arm\",\n\"stddev_yaw_arm\", \"var_yaw_arm\", \"kurtosis_roll_arm\", \"kurtosis_picth_arm\",\n\"kurtosis_yaw_arm\", \"skewness_roll_arm\", \"skewness_pitch_arm\", \"skewness_yaw_arm\",\n\"max_roll_arm\", \"min_roll_arm\", \"min_pitch_arm\", \"amplitude_roll_arm\", \"amplitude_pitch_arm\",\n\"kurtosis_roll_dumbbell\", \"kurtosis_picth_dumbbell\", \"kurtosis_yaw_dumbbell\", \"skewness_roll_dumbbell\",\n\"skewness_pitch_dumbbell\", \"skewness_yaw_dumbbell\", \"max_yaw_dumbbell\", \"min_yaw_dumbbell\",\n\"amplitude_yaw_dumbbell\", \"kurtosis_roll_forearm\", \"kurtosis_picth_forearm\", \"kurtosis_yaw_forearm\",\n\"skewness_roll_forearm\", \"skewness_pitch_forearm\", \"skewness_yaw_forearm\", \"max_roll_forearm\",\n\"max_yaw_forearm\", \"min_roll_forearm\", \"min_yaw_forearm\", \"amplitude_roll_forearm\",\n\"amplitude_yaw_forearm\", \"avg_roll_forearm\", \"stddev_roll_forearm\", \"var_roll_forearm\",\n\"avg_pitch_forearm\", \"stddev_pitch_forearm\", \"var_pitch_forearm\", \"avg_yaw_forearm\",\n\"stddev_yaw_forearm\", \"var_yaw_forearm\")\n\ntraining <- training[!NZVvars]\ndim(training)\n#[1] 11776   100\n#60 variables reduced\n```\n\nDelete first column of Dataset - ID, so that it does not interfere with ML Algorithms:\n\n```{r}\ntraining <- training[c(-1)]\n```\n\nCleaning variables with too many NAs (that have more than a 60% threshold of NAs):\n\n```{r}\ntemp_training <- training \nfor(i in 1:length(training)) { \n        if( sum( is.na( training[, i] ) ) /nrow(training) >= .6 ) { \n  \tfor(j in 1:length(temp_training)) {\n\t\t\tif( length( grep(names(training[i]), names(temp_training)[j]) ) ==1)  {\n\t\t\t\ttemp_training <- temp_training[ , -j] \n\t\t\t}\t\n\t\t} \n\t}\n}\ndim(temp_training)\ntraining <- temp_training\nrm(temp_training)\n```\n\nComplete same transformation for our original_testing and testing data sets.\n\n```{r}\nclean1 <- colnames(training)\nclean2 <- colnames(training[, -58])\ntesting <- testing[clean1]\noriginal_testing <- original_testing[clean2]\ndim(testing); dim(original_testing)\n```\n\nIn order to ensure proper functioning of Decision Trees and especially Random Forest Algorithm with the Test data set (data set provided), we need to coerce the data into the same type.\n\n```{r}\nfor (i in 1:length(original_testing) ) {\n        for(j in 1:length(training)) {\n  \tif( length( grep(names(training[i]), names(original_testing)[j]) ) ==1)  {\n\t\t\tclass(original_testing[j]) <- class(training[i])\n\t\t}      \n\t}      \n}\n\noriginal_testing <- rbind(training[2, -58] , original_testing) #note row 2 does not mean anything, will be removed \noriginal_testing <- original_testing[-1,]\n\n```\n\n## Using ML algorithms for prediction: Decision Tree\n\n```{r}\nmodFitA1 <- rpart(classe ~ ., data=training, method=\"class\")\n```\n\nNote: to view the decision tree with fancy run this command:\n\n```{r}\nfancyRpartPlot(modFitA1)\n```\n\nPredicting:\n\n```{r}\npredictionsA1 <- predict(modFitA1, testing, type = \"class\")\n```\n\nUsing confusion Matrix to test results:\n```{r}\nconfusionMatrix(predictionsA1, testing$classe)\n#Overall Statistics\n                                          \n#               Accuracy : 0.8683          \n#                 95% CI : (0.8607, 0.8757)\n#    No Information Rate : 0.2845          \n#    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n#                  Kappa : 0.8335 \n```\n\n## Using ML algorithms for prediction: Random Forests\n\n```{r}\nmodFitB1 <- randomForest(classe ~. , data=training)\n```\n\nPredicting:\n```{r}\npredictionsB1 <- predict(modFitB1, testing, type = \"class\")\n```\nUsing confusion Matrix to test results:\n```{r}\nconfusionMatrix(predictionsB1, testing$classe)\n#Overall Statistics\n                                         \n #              Accuracy : 0.999          \n #                95% CI : (0.998, 0.9996)\n #   No Information Rate : 0.2845         \n #   P-Value [Acc > NIR] : < 2.2e-16      \n                                         \n #                 Kappa : 0.9987         \n #Mcnemar's Test P-Value : NA \n\n\n```\nRandom Forests has better results, as expected!\n\n## Generating Files to submit as answers for the Assignment:\n\nFinally, using the provided Test Set: for Random Forests is, which has a much better prediction:\n\n```{r}\npredictionsB2 <- predict(modFitB1, original_testing, type = \"class\")\n```\n\nFunction to generate files with predictions to submit for assignment\n```{r}\n\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\n\npml_write_files(predictionsB2)\n```",
    "created" : 1424614642071.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1254192430",
    "id" : "CC3AE6FA",
    "lastKnownWriteTime" : 1424619001,
    "path" : "C:/Documents and Settings/Администратор/datasciencecoursera/Practical Machine Learning/course_project/course_project.rmd",
    "project_path" : "course_project.rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}